{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Credits instructions: https://torchio.readthedocs.io/#credits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchio as tio\n",
    "import time\n",
    "from IPython import display\n",
    "from math import ceil\n",
    "\n",
    "#import pytorch_ssim\n",
    "\n",
    "from Unet import UNet\n",
    "from pretrain_datasets import load_pretrain_datasets,load_kidney_seg\n",
    "from Utils import DiceLoss, dice_ratio, LovaszSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameters\n",
    "\n",
    "num_workers = 6               #number of parallel workers for dataloaders\n",
    "batch_size = 1                #dataloader batch size\n",
    "epochs = 10                    #number of epochs per dataset\n",
    "data_shape = (128,128,128)    #resize all data to this shape\n",
    "num_filters = 32              #number of channels throughout the network\n",
    "\n",
    "rate = .0001\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "#choose dataset order and included sets. 0-braintumor,1-heart,2-liver,3-hippocampus,4-prostate,\n",
    "#5-lung,6-pancreas,7-hepaticvessels,8-spleen,9-colontumor,10-kidney\n",
    "dataset_order = [2,7,8,6,4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data augmentations/transformations\n",
    "#define transformations\n",
    "flip = tio.RandomFlip(p=0.3)\n",
    "spatial = tio.OneOf(\n",
    "    {tio.RandomAffine(): 0.4, \n",
    "     tio.RandomElasticDeformation(): 0.6},p=0.4)\n",
    "noise = tio.RandomNoise(std=(0.05),p=0.3)\n",
    "transform = tio.Compose([flip,spatial])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dataloaders = load_pretrain_datasets(data_shape,batch=batch_size,workers=num_workers,transform=transform)\n",
    "dataloaders.append(load_kidney_seg(data_shape,batch=batch_size,workers=num_workers,transform=transform))\n",
    "\n",
    "#make network\n",
    "net = UNet(1,num_classes,num_filters).cuda()\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m,nn.ConvTranspose3d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "    elif isinstance(m, nn.InstanceNorm3d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "#define loss criteria\n",
    "criterion_bce = torch.nn.BCELoss().cuda()\n",
    "criterion_lova = LovaszSoftmax().cuda()\n",
    "criterion_dice = DiceLoss().cuda()\n",
    "\n",
    "#ssim = pytorch_ssim.SSIM3D().cuda()\n",
    "\n",
    "#learning params\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 6 of 6\n",
      "Epoch: 9 | Batch: 200 -----> Train loss: 1.191116 Cost Time: 8.624786138534546\n",
      "Batch BCE Loss: 0.265333 || Batch Lovasz Loss: 0.100302 || Batch DICE Loss: 0.834664 || \n",
      "Epoch 9 Finished ! Loss is 1.192281\n",
      "Epoch time:  274.9685034751892\n"
     ]
    }
   ],
   "source": [
    "for loadnum,dataset_num in enumerate(dataset_order):\n",
    "    dataloader = dataloaders[dataset_num]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        start_time = time.time() #gets reset each print\n",
    "        epoch_loss = 0.\n",
    "        net.train()\n",
    "        for batch_idx, subject in enumerate(dataloader):\n",
    "            image = subject['img'][tio.DATA].cuda()\n",
    "            label = subject['label'][tio.DATA].cuda()\n",
    "            \n",
    "            label1 = torch.cat(((label==1).float(),(label==2).float()),dim=1).cuda()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = net(image)\n",
    "            \n",
    "            output = torch.sigmoid(output)\n",
    "            \n",
    "            \n",
    "            loss_bce = criterion_bce(output,label1)\n",
    "            loss_lova = 1-criterion_lova(output,label)\n",
    "            loss_dice = criterion_dice(output,label1)\n",
    "            \n",
    "            loss = loss_bce + loss_lova + loss_dice\n",
    "            #loss = (1-ssim(output,label)) #need to minimize dissimilarity\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                print_line = 'Dataset {} of {}\\n' \\\n",
    "                             'Epoch: {} | Batch: {} -----> Train loss: {:4f} Cost Time: {}\\n' \\\n",
    "                             'Batch BCE Loss: {:4f} || ' \\\n",
    "                             'Batch Lovasz Loss: {:4f} || ' \\\n",
    "                             'Batch DICE Loss: {:4f} || ' \\\n",
    "                             .format(loadnum+1,len(dataset_order),e, batch_idx, epoch_loss / (batch_idx + 1),\n",
    "                                     time.time()-start_time, loss_bce.item(),loss_lova.item(),loss_dice.item())\n",
    "                             \n",
    "                print(print_line)\n",
    "                start_time = time.time()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch {} Finished ! Loss is {:4f}'.format(e, epoch_loss / (batch_idx + 1)))\n",
    "\n",
    "        print(\"Epoch time: \", time.time() - epoch_start_time)\n",
    "    #optimizer = torch.optim.Adam(net.parameters(), lr=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "folder_name = '/home/mitch/fewshotlocal/models/pretrain'\n",
    "torch.save(net.state_dict(), folder_name + '/model_{}.pth'.format(timestr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
